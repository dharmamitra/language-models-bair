from datasets import load_dataset, DatasetDict

from lme.data_processors.abstract import AbstractDataProcessor


__all__ = ["SandhiDataProcessor",
           "SandhiLongDataProcessor"]



class SandhiDataProcessor(AbstractDataProcessor):
    """
    Sandhi data processor for sentence-level data

    """

    def load(self) -> DatasetDict:
        dataset = load_dataset("chronbmm/sandhi-split", use_auth_token=True)

        dataset = dataset.rename_columns({
            "input_text": "sentence",
            "target_text": "unsandhied",
        })

        dataset = DatasetDict({
            "train": dataset["train"],
            "val": dataset["validation"],
            "test": dataset["test"],
        })

        return dataset

class SandhiLongDataProcessor(AbstractDataProcessor):
    """
    Sandhi data processor for concatenated sentence-level data

    """

    def load(self) -> DatasetDict:
        dataset = load_dataset("chronbmm/sandhi-split-long", use_auth_token=True)
        # dataset = dataset.rename_columns({
        #     "input_text": "sentence",
        #     "target_text": "unsandhied",
        # })

        dataset = DatasetDict({
            "train": dataset["train"],
            "val": dataset["validation"],
            "test": dataset["test"],
        })
        return dataset
